---
title: "RWorksheet5_(Celestra, Caneso, Arenal)"
output:
  html_document:
    df_print: paged
date: "2024-11-06"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
**[EXTRACTING TV SHOWS REVIEWS]**
```{r}
```
**1.**
```{r}
```
**________________________________________________________**
**Libraries**
```{r}
library(rvest)
library(httr)
library(polite)
library(dplyr)
library(stringr)
library(knitr) 
```

*IMDB URL*
```{r}
polite::use_manners(save_as = 'polite_scrape.R')

url <- "https://www.imdb.com/chart/toptv/?ref_=nv_tvv_250"

session <- bow(url,
user_agent = "Educational")
session

```

*Title List*
```{r}
title_list <- scrape(session) %>%
html_nodes('h3.ipc-title__text') %>%
html_text

title_list_sub <- as.data.frame(title_list[2:26])
title_list_sub
```

*Split*
```{r}
colnames(title_list_sub) <- "ranks"

split_df <- strsplit(as.character(title_list_sub$ranks),".",fixed = T)
split_df <- data.frame(do.call(rbind,split_df))

colnames(split_df) <- c("ranks", "titles")
split_df
```

*Rating*
```{r}
rating_list <- scrape(session) %>%
html_nodes('span.ipc-rating-star--rating') %>%
html_text

```

*Number of People who voted*
```{r}
people_list <- scrape(session) %>%
html_nodes('span.ipc-rating-star--voteCount') %>%
html_text

```

*Episode and Year it was released*
```{r}
episode_list <- scrape(session) %>%
  html_nodes('span.sc-300a8231-7.eaXxft.cli-title-metadata-item:nth-of-type(2)') %>%
  html_text()


year_list <- scrape(session) %>%
  html_nodes('span.sc-300a8231-7.eaXxft.cli-title-metadata-item:nth-of-type(1)') %>%
  html_text()


```

**User Reviews, Critic Reviews, and Popularity Rating**
```{r}
home_link <- 'https://www.imdb.com/chart/toptv/'
main_page <- read_html(home_link)

links <- main_page %>%
  html_nodes("a.ipc-title-link-wrapper") %>%
  html_attr("href")

# Loop to get link of each show's page
show_data <- lapply(links, function(link) {
  complete_link <- paste0("https://imdb.com", link)
  
  #loop to get the link for user review page
  usrv_link <- read_html(complete_link)
  usrv_link_page <- usrv_link %>%
    html_nodes('a.isReview') %>%
    html_attr("href")
  
  #loop to get user reviews of each shows
  usrv <- read_html(paste0("https://imdb.com", usrv_link_page[1]))
  usrv_count <- usrv %>%
    html_nodes('[data-testid="tturv-total-reviews"]') %>%
    html_text()
  
  #loop to extract critic reviews
  critic <- usrv_link %>%
              html_nodes("span.score") %>%
              html_text()
  critic_df <- data.frame(Critic_Reviews = critic[2], stringsAsFactors = FALSE)
  
  #loop to extract pop rating
  pop_rating <- usrv_link %>%
              html_nodes('[data-testid="hero-rating-bar__popularity__score"]') %>%
              html_text()
  pop_rating_df <- data.frame(Popularity_Rating = pop_rating[2], stringsAsFactors = FALSE)
  
  return(data.frame(User_Reviews = usrv_count, Critic = critic_df, pop = pop_rating_df)) 
})

showss <- do.call(rbind, show_data)
```

**FINAL DATA**
```{r}
tv_shows <- data.frame(Ranking = split_df$ranks,
                       TV_Show_Title = split_df$titles,
                       Episodes = episode_list[1:25],
                       Release_Year = year_list[1:25],
                       Rating = rating_list[1:25],
                       No._of_Voter = people_list[1:25],
                       User_Review = showss$User_Reviews,
                       Popularity = showss$Popularity_Rating,
                       Critic_Reviews = showss$Critic_Reviews)
write.csv(tv_shows, "TV_Shows.csv", row.names = F)
```
**________________________________________________________**
```{r}
#just for space
```

**2. Top 5 TV Shows**
```{r}


urls <- c("https://www.imdb.com/title/tt0903747/reviews/?ref_=tt_urv_sm",
          "https://www.imdb.com/title/tt5491994/reviews/?ref_=tt_urv_sm",
          "https://www.imdb.com/title/tt0795176/reviews/?ref_=tt_urv_sm",
          "https://www.imdb.com/title/tt0185906/reviews/?ref_=tt_urv_sm",
          "https://www.imdb.com/title/tt7366338/reviews/?ref_=tt_urv_sm")

df <- list()

for(i in seq_along(urls)){
  
  sessions <- bow(urls[i], user_agent = "Educational")

#User name
userName <- scrape(sessions) %>%
html_nodes('a.ipc-link.ipc-link--base') %>%
html_text() %>%
  head(20)

#Date reviewed
dateReview <- scrape(sessions) %>%
html_nodes('li.ipc-inline-list__item.review-date') %>%
html_text() %>%
  head(20)

#User rating
userRating <- scrape(sessions) %>%
html_nodes('span.ipc-rating-star--rating') %>%
html_text() %>%
  head(20)

#Title of the review
reviewTitle <- scrape(sessions) %>%
html_nodes('h3.ipc-title__text') %>%
html_text() %>%
  head(20)

#Helpful
helpful <- scrape(sessions) %>%
html_nodes('span.ipc-voting__label') %>%
html_text()

#Unhelpful
unhelpful <- scrape(sessions) %>%
html_nodes('span.ipc-voting__label__count.ipc-voting__label__count--down') %>%
html_text() 

#Data frame for the user reviews.
userReviews <- data.frame(user_Name = userName[1:20],
                          Date_Reviewed = dateReview[1:20],
                          user_Rating = userRating[1:20],
                          Review_Title = reviewTitle[1:20],
                          Helpful = helpful[1:20],
                          Unhelpful = unhelpful[1:20],
                          stringsAsFactors = F)

df[[i]] <- userReviews
}

df[[1]]
df[[2]]
df[[3]]
df[[4]]
df[[5]]
```
**________________________________________________________**
```{r}
#just for space
```

**3.**
```{r}
library(ggplot2)
years <- substr(year_list, 1,4)
years <- as.numeric(years)      

ggplot(data.frame(Year = years), aes(x = Year)) +
  geom_line(stat = "count", fill = "skyblue", color = "blue") +
  labs(title = "Number of TV Shows Released by Year",
       x = "Year",
       y = "Number of TV Shows") +
  theme_minimal()

most_shows_year <- as.data.frame(table(years))
most_shows_year <- most_shows_year[which.max(most_shows_year$Freq), ]
print(most_shows_year)

```





**_______________________________________________________________________________________________**
```{r}
#just for space
```

4-5.
**[EXTRACTING AMAZON PRODUCT REVIEWS]**

**Graphics Card**
```{r}

  gc_url <- c("https://www.amazon.com/s?k=graphics+card&crid=6809YKENO5VZ&sprefix=graphics+%2Caps%2C516&ref=nb_sb_ss_ts-doa-p_1_9",
            "https://www.amazon.com/s?k=graphics+card&page=2&crid=NY6LX0H811DR&qid=1732062550&sprefix=%2Caps%2C1816&ref=sr_pg_2")

graphics <- list()

for(i in seq_along(gc_url)){
  Sys.sleep(2)
  gSession <- bow(gc_url[i], user_agent = "Educational")
  
  # Scrape data
  product_titles <- scrape(gSession) %>%
    html_nodes("span.a-text-normal") %>% 
    html_text() %>%
    head(30)
  product_titles <- product_titles[!grepl("Check each product page for other buying options", product_titles)]
  
  price <- scrape(gSession) %>% 
    html_nodes('.a-price .a-offscreen') %>% 
    html_text() %>%
    head(30)
  price <- as.numeric(str_extract(price, "\\d+\\.\\d"))
  
  ratings <- scrape(gSession) %>% 
    html_nodes('span.a-icon-alt') %>% 
    html_text() %>%
    head(30)
 ratings <- as.numeric(str_extract(ratings, "\\d+\\.\\d"))
  
  reviews <- scrape(gSession) %>%
    html_nodes('.s-link-style .s-underline-text') %>% 
    html_text() %>%
    head(30)
  
  descriptions <- scrape(gSession) %>%
    html_nodes('.a-row.a-size-base.a-color-secondary') %>% 
    html_text() %>%
    head(30)
  
  # Find the maximum length
  max_length <- max(
    length(product_titles), length(price), length(ratings),
    length(reviews), length(descriptions)
  )
  
  # Standardize all vectors to the same length
  length(product_titles) <- max_length
  length(price) <- max_length
  length(ratings) <- max_length
  length(reviews) <- max_length
  length(descriptions) <- max_length
  
  # Create a data frame
  card <- data.frame(
    ProductTitle = product_titles[1:15],
    Price = price[1:15],
    Ratings = ratings[1:15],
    Reviews = reviews[1:15],
    Description = descriptions[1:15],
    stringsAsFactors = FALSE
  )
  
graphics[[i]] <- card
}
```
```{r}
Gcard <- rbind(graphics[[1]], graphics[[2]])

kable(Gcard, caption = "Graphics Card Category")
```
```{r}
write.csv(Gcard, "Gcard.csv", row.names = F)
```


**Laptop**
```{r}
lap_url <- c("https://www.amazon.com/s?k=laptop&crid=15FICF43OPKJ2&sprefix=laptop%2Caps%2C1359&ref=nb_sb_ss_ts-doa-p_1_6",
            "https://www.amazon.com/s?k=laptop&page=2&crid=15FICF43OPKJ2&qid=1732065167&sprefix=laptop%2Caps%2C1359&ref=sr_pg_2")

laptop <- list()

for(i in seq_along(lap_url)){
  
  gSession <- bow(lap_url[i], user_agent = "Educational")
  
  # Scrape data
  product_titles <- scrape(gSession) %>%
    html_nodes("span.a-text-normal") %>% 
    html_text() %>%
    head(30)
  product_titles <- product_titles[!grepl("Check each product page for other buying options", product_titles)]
  
  price <- scrape(gSession) %>% 
    html_nodes('.a-price .a-offscreen') %>% 
    html_text() %>%
    head(30)
  price <- as.numeric(str_extract(price, "\\d+\\.\\d"))
  
  ratings <- scrape(gSession) %>% 
    html_nodes('span.a-icon-alt') %>% 
    html_text() %>%
    head(30)
  ratings <- as.numeric(str_extract(ratings, "\\d+\\.\\d"))
  
  reviews <- scrape(gSession) %>%
    html_nodes('.s-link-style .s-underline-text') %>% 
    html_text() %>%
    head(30)
  
  descriptions <- scrape(gSession) %>%
    html_nodes('.a-row.a-size-base.a-color-secondary') %>% 
    html_text() %>%
    head(30)
  
  # Find the maximum length
  max_length <- max(
    length(product_titles), length(price), length(ratings),
    length(reviews), length(descriptions)
  )
  
  # Standardize all vectors to the same length
  length(product_titles) <- max_length
  length(price) <- max_length
  length(ratings) <- max_length
  length(reviews) <- max_length
  length(descriptions) <- max_length
  
  # Create a data frame
  lappy <- data.frame(
    ProductTitle = product_titles[1:15],
    Price = price[1:15],
    Ratings = ratings[1:15],
    Reviews = reviews[1:15],
    Description = descriptions[1:15],
    stringsAsFactors = FALSE
  )
  
laptop[[i]] <- lappy
}
```
```{r}
laptops <- rbind(laptop[[1]], laptop[[2]])

kable(laptops, caption = "Laptop Category")
```
```{r}
write.csv(laptops, "Laptop.csv", row.names = F)
```


**PC Case**
```{r}

pc_url <- c("https://www.amazon.com/s?k=pc+cases&crid=3232B9XX8J30L&sprefix=pccase%2Caps%2C674&ref=nb_sb_ss_ts-doa-p_3_6",
            "https://www.amazon.com/s?k=pc+cases&page=2&crid=3232B9XX8J30L&qid=1732066185&sprefix=pccase%2Caps%2C674&ref=sr_pg_2")

case <- list()

for(i in seq_along(pc_url)){
  Sys.sleep(2)
  gSession <- bow(pc_url[i], user_agent = "Educational")
  
  # Scrape data
  product_titles <- scrape(gSession) %>%
    html_nodes("span.a-text-normal") %>% 
    html_text() %>%
    head(30)
  product_titles <- product_titles[!grepl("Check each product page for other buying options", product_titles)]
  
  price <- scrape(gSession) %>% 
    html_nodes('.a-price .a-offscreen') %>% 
    html_text() %>%
    head(30)
  price <- as.numeric(str_extract(price, "\\d+\\.\\d"))
  
  ratings <- scrape(gSession) %>% 
    html_nodes('span.a-icon-alt') %>% 
    html_text() %>%
    head(30)
  ratings <- as.numeric(str_extract(ratings, "\\d+\\.\\d"))
  
  reviews <- scrape(gSession) %>%
    html_nodes('.s-link-style .s-underline-text') %>% 
    html_text() %>%
    head(30)
  
  descriptions <- scrape(gSession) %>%
    html_nodes('.a-row.a-size-base.a-color-secondary') %>% 
    html_text() %>%
    head(30)
  
  # Find the maximum length
  max_length <- max(
    length(product_titles), length(price), length(ratings),
    length(reviews), length(descriptions)
  )
  
  # Standardize all vectors to the same length
  length(product_titles) <- max_length
  length(price) <- max_length
  length(ratings) <- max_length
  length(reviews) <- max_length
  length(descriptions) <- max_length
  
  # Create a data frame
  pCase <- data.frame(
    ProductTitle = product_titles[1:15],
    Price = price[1:15],
    Ratings = ratings[1:15],
    Reviews = reviews[1:15],
    Description = descriptions[1:15],
    stringsAsFactors = FALSE
  )
  
case[[i]] <- pCase
}
```
```{r}
pcCase <- rbind(case[[1]], case[[2]])

kable(pcCase, caption = "PC Case Category")
```
```{r}
write.csv(pcCase, "PC_Case.csv", row.names = F)
```


**Monitors**
```{r}

monitor_url <- c("https://www.amazon.com/s?k=monitors&crid=UGL8HSJMO1RM&qid=1732067471&refresh=1&sprefix=monitors%2Caps%2C588&ref=sr_pg_1",
               "https://www.amazon.com/s?k=monitors&page=2&crid=UGL8HSJMO1RM&qid=1732067581&refresh=1&sprefix=monitors%2Caps%2C588&ref=sr_pg_2")

mon <- list()

for(i in seq_along(monitor_url)){
  Sys.sleep(2)
  gSession <- bow(monitor_url[i], user_agent = "Educational")
  
  # Scrape data
  product_titles <- scrape(gSession) %>%
    html_nodes("span.a-text-normal") %>% 
    html_text() %>%
    head(30)
  product_titles <- product_titles[!grepl("Check each product page for other buying options", product_titles)]
  
  price <- scrape(gSession) %>% 
    html_nodes('.a-price .a-offscreen') %>% 
    html_text() %>%
    head(30)
  price <- as.numeric(str_extract(price, "\\d+\\.\\d"))
  
  ratings <- scrape(gSession) %>% 
    html_nodes('span.a-icon-alt') %>% 
    html_text() %>%
    head(30)
  ratings <- as.numeric(str_extract(ratings, "\\d+\\.\\d"))
  
  reviews <- scrape(gSession) %>%
    html_nodes('.s-link-style .s-underline-text') %>% 
    html_text() %>%
    head(30)
  
  descriptions <- scrape(gSession) %>%
    html_nodes('.a-row.a-size-base.a-color-secondary') %>% 
    html_text() %>%
    head(30)
  
  # Find the maximum length
  max_length <- max(
    length(product_titles), length(price), length(ratings),
    length(reviews), length(descriptions)
  )
  
  # Standardize all vectors to the same length
  length(product_titles) <- max_length
  length(price) <- max_length
  length(ratings) <- max_length
  length(reviews) <- max_length
  length(descriptions) <- max_length
  
  # Create a data frame
  moni <- data.frame(
    ProductTitle = product_titles[1:15],
    Price = price[1:15],
    Ratings = ratings[1:15],
    Reviews = reviews[1:15],
    Description = descriptions,
    stringsAsFactors = FALSE
  )
  
mon[[i]] <- moni
}
```
```{r}
mOnitor <- rbind(mon[[1]], mon[[2]])

kable(mOnitor, caption = "Monitor Category")
```
```{r}
write.csv(mOnitor, "Monitor.csv", row.names = F)
```


**CPU**
```{r}

cpu_url <- c("https://www.amazon.com/s?k=cpu&crid=3DBICI2YNNKHJ&sprefix=cpu%2Caps%2C768&ref=nb_sb_noss_1",
               "https://www.amazon.com/s?k=cpu&page=2&crid=3DBICI2YNNKHJ&qid=1732067707&sprefix=cpu%2Caps%2C768&ref=sr_pg_2")

processor <- list()

for(i in seq_along(cpu_url)){
  Sys.sleep(2)
  gSession <- bow(cpu_url[i], user_agent = "Educational")
  
  # Scrape data
  product_titles <- scrape(gSession) %>%
    html_nodes("span.a-text-normal") %>% 
    html_text() %>%
    head(30)
  product_titles <- product_titles[!grepl("Check each product page for other buying options", product_titles)]
  
  price <- scrape(gSession) %>% 
    html_nodes('.a-price .a-offscreen') %>% 
    html_text() %>%
    head(30)
  price <- as.numeric(str_extract(price, "\\d+\\.\\d"))
  
  ratings <- scrape(gSession) %>% 
    html_nodes('span.a-icon-alt') %>% 
    html_text() %>%
    head(30)
  ratings <- as.numeric(str_extract(ratings, "\\d+\\.\\d"))
  
  reviews <- scrape(gSession) %>%
    html_nodes('.s-link-style .s-underline-text') %>% 
    html_text() %>%
    head(30)
  
  descriptions <- scrape(gSession) %>%
    html_nodes('.a-row.a-size-base.a-color-secondary') %>% 
    html_text() %>%
    head(30)
  
  # Find the maximum length
  max_length <- max(
    length(product_titles), length(price), length(ratings),
    length(reviews), length(descriptions)
  )
  
  # Standardize all vectors to the same length
  length(product_titles) <- max_length
  length(price) <- max_length
  length(ratings) <- max_length
  length(reviews) <- max_length
  length(descriptions) <- max_length
  
  # Create a data frame
  process <- data.frame(
    ProductTitle = product_titles[1:15],
    Price = price[1:15],
    Ratings = ratings[1:15],
    Reviews = reviews[1:15],
    Description = descriptions,
    stringsAsFactors = FALSE
  )
  
processor[[i]] <- process
}
```
```{r}
proc <- rbind(processor[[1]], processor[[2]])

kable(proc, caption = "CPU Category")
```
```{r}
write.csv(proc, "CPU.csv", row.names = F)
```

6.
The extracted dataset contains information on 150 products across five categories: Laptops, CPU, Graphics Card, Monitors, and PC Cases, with 30 products selected from each category. For each product, the dataset includes the price, description, ratings, and reviews.The product title contains a string which shows the name of the product. The price is represented as a numeric value indicating the cost of the product. The ratings are numerical, ranging from 0 to 5, and reflect the average customer satisfaction score.The reviews field contains an integer representing the total number of customer reviews. Finally, the description is a text field providing a brief overview of the product's features

7.
Competitive Benchmarking and Pricing Trends Analysis:
The dataset enables businesses to perform competitive benchmarking by comparing product prices within and across categories (e.g., laptops, CPUs, graphics cards, monitors, and PC cases). By analyzing pricing trends, businesses can gain critical insights into market positioning and consumer preferences.

8.
```{r}
library(ggplot2)

# Read the CSV files and calculate the mean price for each category
cpu_price <- read.csv("CPU.csv")
gcard_price <- read.csv("Gcard.csv")
laptop_price <- read.csv("Laptop.csv")
monitor_price <- read.csv("Monitor.csv")
PCcase_price <- read.csv("PC_Case.csv")

# Calculate the mean price for each category
mean_cpu <- mean(cpu_price$Price)
mean_gcard <- mean(gcard_price$Price)
mean_laptop <- mean(laptop_price$Price)
mean_monitor <- mean(monitor_price$Price)
mean_pc_case <- mean(PCcase_price$Price)

# Create a data frame to store the average prices
avg_prices <- data.frame(
  Category = c("CPU", "Graphics Card", "Laptop", "Monitor", "PC Case"),
  Average_Price = c(mean_cpu, mean_gcard, mean_laptop, mean_monitor, mean_pc_case)
)

# Create the bar plot
ggplot(avg_prices, aes(x = Category, y = Average_Price, fill = Category)) +
  geom_bar(stat = "identity") +
  labs(title = "Average Price Comparison by Category",
       x = "Product Category", 
       y = "Average Price ($)") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))  


```
The graph provides valuable insights into competitive benchmarking and pricing trends across different product categories in the computing market. Laptops stand out as the most expensive category, with an average price exceeding $300, indicating their premium nature and potential for higher profit margins. CPUs and graphics cards fall into a similar pricing tier, both averaging slightly above $200, which could reflect their high demand among gamers and professionals building custom systems. Monitors, priced around $150 on average, are moderately positioned, suggesting they cater to a broad range of users with varying budgets. Finally, PC cases are the least expensive category, averaging under $100, highlighting their relatively low-cost nature compared to other components. These insights are crucial for businesses looking to align their pricing strategies with market trends and remain competitive in these product segments.

9.
```{r}
# Load the necessary library
library(ggplot2)

# Read the data
cpu_price <- read.csv("CPU.csv")
gcard_price <- read.csv("Gcard.csv")
laptop_price <- read.csv("Laptop.csv")
monitor_price <- read.csv("Monitor.csv")
PCcase_price <- read.csv("PC_Case.csv")

# Combine the data for price and ratings into one data frame
price_data <- data.frame(
  Category = rep(c("CPU", "Graphics Card", "Laptop", "Monitor", "PC Case"), 
                 times = c(nrow(cpu_price), nrow(gcard_price), nrow(laptop_price), nrow(monitor_price), nrow(PCcase_price))),
  Price = c(cpu_price$Price, gcard_price$Price, laptop_price$Price, monitor_price$Price, PCcase_price$Price),
  Ratings = c(cpu_price$Ratings, gcard_price$Ratings, laptop_price$Ratings, monitor_price$Ratings, PCcase_price$Ratings)
)

# Price Plot using ggplot2
price_plot <- ggplot(price_data, aes(x = Category, y = Price, fill = Category)) +
  geom_boxplot() +
  labs(title = "Price by Category", y = "Price ($)", x = "Category") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotate x-axis labels for readability

# Ratings Plot using ggplot2
ratings_plot <- ggplot(price_data, aes(x = Category, y = Ratings, fill = Category)) +
  geom_boxplot() +
  labs(title = "Ratings by Category", y = "Ratings", x = "Category") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotate x-axis labels for readability

# Print the plots side by side
library(gridExtra)
grid.arrange(price_plot, ratings_plot, ncol = 2)


```
10.
```{r}
# Rank products by price and ratings for each category

# Rank by price (highest to lowest)
cpu_price$Price_Rank <- rank(-cpu_price$Price)  # Negative sign for descending order
gcard_price$Price_Rank <- rank(-gcard_price$Price)
laptop_price$Price_Rank <- rank(-laptop_price$Price)
monitor_price$Price_Rank <- rank(-monitor_price$Price)
PCcase_price$Price_Rank <- rank(-PCcase_price$Price)

# Rank by ratings (highest to lowest)
cpu_price$Rating_Rank <- rank(-cpu_price$Ratings)  
gcard_price$Rating_Rank <- rank(-gcard_price$Ratings)
laptop_price$Rating_Rank <- rank(-laptop_price$Ratings)
monitor_price$Rating_Rank <- rank(-monitor_price$Ratings)
PCcase_price$Rating_Rank <- rank(-PCcase_price$Ratings)

# View the top ranked products for each category 
head(cpu_price)
head(gcard_price)
head(laptop_price)
head(monitor_price)
head(PCcase_price)

```
Ranking products by price and ratings provides insights into how cost and customer satisfaction relate. The price rank identifies the most expensive products, often premium options, but doesn't necessarily reflect customer satisfaction. In contrast, the rating rank shows which products are most highly regarded by consumers, regardless of their price. Comparing these rankings helps highlight whether consumers prioritize cost or quality. For example, in Laptops, mid-range models may have higher ratings despite lower prices, while in PC Cases, budget-friendly products could be highly rated for their value and functionality. This comparison aids in understanding the balance between price and quality in each category.
